# 17ç§PIIæ¨¡å‹è®­ç»ƒæŒ‡å—

æœ¬æ–‡æ¡£ç”¨äºåœ¨å…¶ä»–è®¾å¤‡ä¸Šè¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚

---

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
2. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
3. [è®­ç»ƒæ‰§è¡Œ](#è®­ç»ƒæ‰§è¡Œ)
4. [éªŒè¯æµ‹è¯•](#éªŒè¯æµ‹è¯•)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡

### ç¡¬ä»¶è¦æ±‚

- **GPU**: NVIDIA GPUï¼ˆæ¨èRTX 3060åŠä»¥ä¸Šï¼Œ12GB+ VRAMï¼‰
- **å†…å­˜**: 32GB+ RAM
- **å­˜å‚¨**: 50GB+ å¯ç”¨ç©ºé—´

### è½¯ä»¶ä¾èµ–

```bash
# 1. åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# 2. å®‰è£…æ ¸å¿ƒä¾èµ–
pip install torch==2.8.0+cu128 --index-url https://download.pytorch.org/whl/cu128
pip install transformers==4.56.2
pip install unsloth[cu128-ampere-torch280]
pip install datasets accelerate peft bitsandbytes

# 3. å®‰è£…é¡¹ç›®ä¾èµ–
cd HPPE
pip install -e .
```

### éªŒè¯ç¯å¢ƒ

```bash
python -c "import torch; print('CUDAå¯ç”¨:', torch.cuda.is_available())"
python -c "import torch; print('GPUæ•°é‡:', torch.cuda.device_count())"
python -c "import torch; print('GPUåç§°:', torch.cuda.get_device_name(0))"
```

---

## ğŸ“Š æ•°æ®å‡†å¤‡

### æ ‡å‡†PIIç±»å‹

é¡¹ç›®æ”¯æŒ**17ç§æ ‡å‡†PIIç±»å‹**ï¼ˆå®šä¹‰åœ¨ `src/hppe/models/pii_types.py`ï¼‰ï¼š

| **Phase 1 (6ç§)** | **Phase 2 (11ç§)** |
|-------------------|-------------------|
| PERSON_NAME      | BANK_CARD         |
| PHONE_NUMBER     | PASSPORT          |
| EMAIL            | DRIVER_LICENSE    |
| ADDRESS          | VEHICLE_PLATE     |
| ORGANIZATION     | IP_ADDRESS        |
| ID_CARD          | MAC_ADDRESS       |
|                  | POSTAL_CODE       |
|                  | IMEI              |
|                  | VIN               |
|                  | TAX_ID            |
|                  | SOCIAL_SECURITY   |

### æ•°æ®æ ¼å¼

è®­ç»ƒæ•°æ®ä½¿ç”¨JSONLæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰ï¼š

```json
{
  "text": "æˆ‘æ˜¯å¼ ä¸‰ï¼Œç”µè¯13812345678",
  "entities": [
    {
      "type": "PERSON_NAME",
      "value": "å¼ ä¸‰",
      "start": 2,
      "end": 4,
      "confidence": 1.0
    },
    {
      "type": "PHONE_NUMBER",
      "value": "13812345678",
      "start": 7,
      "end": 18,
      "confidence": 1.0
    }
  ],
  "metadata": {
    "context": "self-introduction",
    "language": "zh"
  }
}
```

### ç”Ÿæˆè®­ç»ƒæ•°æ®

#### æ–¹æ³•1ï¼šä½¿ç”¨æ•°æ®æ¨¡æ¿ï¼ˆå¿«é€Ÿå¼€å§‹ï¼‰

```bash
# ç”Ÿæˆæ ‡å‡†è®­ç»ƒæ•°æ®æ¨¡æ¿ï¼ˆ36ä¸ªæ ·æœ¬ï¼‰
python scripts/generate_training_data_template.py

# è¾“å‡ºï¼šdata/training/17pii_training_template.jsonl
```

#### æ–¹æ³•2ï¼šæ‰©å±•çœŸå®æ•°æ®ï¼ˆç”Ÿäº§çº§ï¼‰

åŸºäºç°æœ‰çš„è®­ç»ƒæ•°æ®ç”Ÿæˆè„šæœ¬æ‰©å±•ï¼š

```bash
# å‚è€ƒç°æœ‰è„šæœ¬
scripts/generate_11pii_training_data.py

# å»ºè®®ç”Ÿæˆæ•°é‡ï¼š
# - Phase 1 (6ç§): 500-1000 æ ·æœ¬/ç±»å‹
# - Phase 2 (11ç§): 300-500 æ ·æœ¬/ç±»å‹
# æ€»è®¡ï¼šçº¦8,000-15,000 æ ·æœ¬
```

**æ‰©å±•æ ·æœ¬ç¤ºä¾‹**ï¼š

```python
import sys
from pathlib import Path
sys.path.insert(0, str(Path.cwd() / "src"))

from hppe.models.pii_types import PIIType, ALL_17_TYPES

# ä¸ºæ¯ç§ç±»å‹ç”Ÿæˆå¤šæ ·åŒ–æ ·æœ¬
for pii_type in ALL_17_TYPES:
    samples = generate_samples_for_type(pii_type, count=500)
    # ä½¿ç”¨ä¸åŒçš„ä¸Šä¸‹æ–‡ã€è¡¨è¾¾æ–¹å¼ã€æ ¼å¼å˜åŒ–
    # æ·»åŠ å™ªå£°ã€æ··åˆæ ·æœ¬ã€è¾¹ç¼˜æ¡ˆä¾‹
```

### æ•°æ®éªŒè¯

```bash
# éªŒè¯æ•°æ®ä¸€è‡´æ€§
python scripts/validate_data_consistency.py

# åº”è¾“å‡ºï¼š
# âœ… æ‰€æœ‰æ–‡ä»¶éªŒè¯é€šè¿‡ï¼
```

---

## ğŸš€ è®­ç»ƒæ‰§è¡Œ

### è®­ç»ƒè„šæœ¬

ä½¿ç”¨ Unsloth æ¡†æ¶è¿›è¡Œé«˜æ•ˆè®­ç»ƒï¼š

```bash
# å•GPUè®­ç»ƒï¼ˆæ¨èï¼‰
CUDA_VISIBLE_DEVICES=0 python scripts/train_pii_detector_unsloth_fixed.py \
    --model_name Qwen/Qwen2.5-3B-Instruct \
    --data_path data/training/17pii_training_data.jsonl \
    --output_dir models/pii_qwen4b_17types_final \
    --num_epochs 3 \
    --batch_size 4 \
    --learning_rate 2e-5 \
    --lora_r 16 \
    --lora_alpha 32 \
    --max_seq_length 2048 \
    --gradient_accumulation_steps 4
```

### å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| `--model_name` | åŸºç¡€æ¨¡å‹ | `Qwen/Qwen2.5-3B-Instruct` |
| `--num_epochs` | è®­ç»ƒè½®æ•° | 3-5 |
| `--batch_size` | æ‰¹å¤§å° | 4 (12GB VRAM) |
| `--learning_rate` | å­¦ä¹ ç‡ | 2e-5 |
| `--lora_r` | LoRAç§© | 16 |
| `--lora_alpha` | LoRA alpha | 32 |
| `--max_seq_length` | æœ€å¤§åºåˆ—é•¿åº¦ | 2048 |
| `--gradient_accumulation_steps` | æ¢¯åº¦ç´¯ç§¯ | 4 |

### è®­ç»ƒæ—¶é•¿é¢„ä¼°

**åŸºäºå†å²æ•°æ®**ï¼ˆRTX 3060 12GBï¼‰ï¼š

- **æ•°æ®é‡**: 8,000 æ ·æœ¬
- **è®­ç»ƒé…ç½®**: 3 epochs, batch_size=4, gradient_accumulation=4
- **é¢„è®¡æ—¶é•¿**: **20-24 å°æ—¶**

**ä¼˜åŒ–å»ºè®®**ï¼š

- ä½¿ç”¨æ›´å¼ºGPUï¼ˆRTX 4090/A100ï¼‰å¯å‡å°‘è‡³ 8-12 å°æ—¶
- å‡å°‘epochsè‡³2å¯å‡å°‘30%æ—¶é—´
- å¢åŠ batch_sizeï¼ˆéœ€æ›´å¤§VRAMï¼‰å¯åŠ é€Ÿè®­ç»ƒ

### ç›‘æ§è®­ç»ƒè¿›åº¦

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/train_17pii_full_*.log

# å…³é”®æŒ‡æ ‡ï¼š
# - loss: é€æ­¥ä¸‹é™ï¼ˆç›®æ ‡ < 0.1ï¼‰
# - learning_rate: é€æ­¥è¡°å‡
# - epoch: å½“å‰è®­ç»ƒè½®æ•°
# - samples/sec: è®­ç»ƒé€Ÿåº¦

# ç›‘æ§GPUä½¿ç”¨ç‡
nvidia-smi -l 5  # æ¯5ç§’åˆ·æ–°
```

---

## âœ… éªŒè¯æµ‹è¯•

### å¿«é€ŸåŠŸèƒ½æµ‹è¯•

```bash
# GPU0å¿«é€Ÿæµ‹è¯•ï¼ˆ10ä¸ªæ ·æœ¬ï¼‰
python examples/quick_test_17pii_gpu0.py

# é¢„æœŸè¾“å‡ºï¼š
# ğŸ“Š æµ‹è¯•ç»“æœ: 10/10 é€šè¿‡
# âœ… 17ç§PIIæ¨¡å‹åŸºæœ¬åŠŸèƒ½æ­£å¸¸ï¼
```

### æ¨¡å‹å¯¹æ¯”éªŒè¯

```bash
# 6ç§ vs 17ç§æ¨¡å‹å¯¹æ¯”
python scripts/compare_6vs17_models.py \
    --model-6pii "models/pii_qwen4b_unsloth/final" \
    --model-17pii "models/pii_qwen4b_17types_final/final" \
    --test-data "data/test_datasets/17pii_test_cases.jsonl" \
    --output "comparison_report.json"

# é¢„æœŸç»“æœï¼š
# - Precision: 60%+ (ç›®æ ‡ 70%+)
# - Recall: 60%+ (ç›®æ ‡ 70%+)
# - F1-Score: 60%+ (ç›®æ ‡ 70%+)
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# å»¶è¿Ÿã€ååé‡ã€æ˜¾å­˜æµ‹è¯•
pytest tests/benchmark/test_llm_performance.py -v

# æµ‹è¯•å†…å®¹ï¼š
# - P50/P95/P99å»¶è¿Ÿ
# - RPSååé‡
# - GPUæ˜¾å­˜å ç”¨
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: CUDA Out of Memory

**ç—‡çŠ¶**ï¼š`RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# 1. å‡å°batch_size
--batch_size 2  # ä»4é™è‡³2

# 2. å¢åŠ æ¢¯åº¦ç´¯ç§¯
--gradient_accumulation_steps 8  # ä»4å¢è‡³8

# 3. å‡å°‘åºåˆ—é•¿åº¦
--max_seq_length 1024  # ä»2048é™è‡³1024

# 4. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆæ›´æ…¢ä½†çœå†…å­˜ï¼‰
--gradient_checkpointing True
```

### Q2: è®­ç»ƒlossä¸ä¸‹é™

**ç—‡çŠ¶**ï¼šlossåœ¨1.0ä»¥ä¸Šéœ‡è¡

**åŸå› **ï¼š

1. å­¦ä¹ ç‡è¿‡é«˜/è¿‡ä½
2. æ•°æ®è´¨é‡é—®é¢˜
3. æ ·æœ¬æ•°é‡ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. è°ƒæ•´å­¦ä¹ ç‡
--learning_rate 1e-5  # é™ä½å­¦ä¹ ç‡

# 2. æ£€æŸ¥æ•°æ®è´¨é‡
python scripts/validate_data_consistency.py

# 3. å¢åŠ è®­ç»ƒæ•°æ®
# ç›®æ ‡ï¼šæ¯ç§ç±»å‹ â‰¥ 300 æ ·æœ¬
```

### Q3: æ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯

**ç—‡çŠ¶**ï¼šæ¨¡å‹è¾“å‡ºä¸æ˜¯æœ‰æ•ˆJSON

**åŸå› **ï¼šPromptè®¾è®¡æˆ–è®­ç»ƒæ•°æ®é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# æ£€æŸ¥è®­ç»ƒæ•°æ®çš„promptæ ¼å¼
# ç¡®ä¿æ¯ä¸ªæ ·æœ¬éƒ½æœ‰æ­£ç¡®çš„instruction format:

{
  "messages": [
    {
      "role": "system",
      "content": "ä½ æ˜¯PIIæ£€æµ‹ä¸“å®¶..."
    },
    {
      "role": "user",
      "content": "æ–‡æœ¬ï¼šæˆ‘æ˜¯å¼ ä¸‰"
    },
    {
      "role": "assistant",
      "content": "{\"entities\": [{\"type\": \"PERSON_NAME\", ...}]}"
    }
  ]
}
```

### Q4: æ¨ç†é€Ÿåº¦æ…¢

**ç—‡çŠ¶**ï¼šå•æ¬¡æ¨ç† > 2ç§’

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š

```python
# 1. ä½¿ç”¨4-bité‡åŒ–
engine = QwenFineTunedEngine(
    model_path="models/pii_qwen4b_17types_final/final",
    device="cuda",
    load_in_4bit=True  # å¯ç”¨4-bité‡åŒ–
)

# 2. å‡å°‘max_new_tokens
generate(..., max_new_tokens=512)  # ä»1024é™è‡³512

# 3. æ‰¹é‡æ¨ç†
texts = ["æ–‡æœ¬1", "æ–‡æœ¬2", ...]
results = engine.batch_detect(texts)
```

### Q5: ç±»å‹åç§°ä¸ä¸€è‡´

**ç—‡çŠ¶**ï¼šæ¨¡å‹è¾“å‡º `LICENSE_PLATE` è€Œé `VEHICLE_PLATE`

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# 1. ä½¿ç”¨ç±»å‹æ ‡å‡†åŒ–å‡½æ•°
from hppe.models.pii_types import normalize_pii_type

predicted_type = "LICENSE_PLATE"
standard_type = normalize_pii_type(predicted_type)
# è¾“å‡º: "VEHICLE_PLATE"

# 2. é‡æ–°è®­ç»ƒä½¿ç”¨æ ‡å‡†ç±»å‹
# ç¡®ä¿è®­ç»ƒæ•°æ®å…¨éƒ¨ä½¿ç”¨æ ‡å‡†ç±»å‹åç§°
```

---

## ğŸ“š å‚è€ƒèµ„æº

### é¡¹ç›®æ–‡æ¡£

- **æ ‡å‡†PIIç±»å‹å®šä¹‰**: `src/hppe/models/pii_types.py`
- **Epic 2å®ŒæˆæŠ¥å‘Š**: `EPIC_2_COMPLETION_REPORT.md`
- **éªŒè¯æŠ¥å‘Š**: `comparison_6vs17_report_*.json`

### ç›¸å…³è„šæœ¬

- **æ•°æ®æ ‡å‡†åŒ–**: `scripts/normalize_test_dataset.py`
- **æ•°æ®ç”Ÿæˆ**: `scripts/generate_training_data_template.py`
- **æ•°æ®éªŒè¯**: `scripts/validate_data_consistency.py`
- **æ¨¡å‹å¯¹æ¯”**: `scripts/compare_6vs17_models.py`

### è®­ç»ƒæ—¥å¿—ç¤ºä¾‹

```
Epoch 1/3:  25%|â–ˆâ–ˆâ–ˆâ–      | 500/2000 [12:30<37:30, 0.66it/s, loss=0.847]
Epoch 1/3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1000/2000 [25:00<25:00, 0.67it/s, loss=0.523]
Epoch 1/3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1500/2000 [37:30<12:30, 0.67it/s, loss=0.312]
Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [50:00<00:00, 0.67it/s, loss=0.185]

âœ… Epoch 1 å®Œæˆï¼Œå¹³å‡loss: 0.441
```

---

## ğŸ¯ è®­ç»ƒæ£€æŸ¥æ¸…å•

**å¼€å§‹è®­ç»ƒå‰**ï¼š

- [ ] GPUç¯å¢ƒéªŒè¯é€šè¿‡
- [ ] è®­ç»ƒæ•°æ®å·²ç”Ÿæˆï¼ˆâ‰¥5,000æ ·æœ¬ï¼‰
- [ ] æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡
- [ ] ç£ç›˜ç©ºé—´å……è¶³ï¼ˆâ‰¥50GBï¼‰
- [ ] è®­ç»ƒå‚æ•°å·²é…ç½®

**è®­ç»ƒè¿‡ç¨‹ä¸­**ï¼š

- [ ] ç›‘æ§lossä¸‹é™è¶‹åŠ¿
- [ ] ç›‘æ§GPUåˆ©ç”¨ç‡ï¼ˆ>80%ï¼‰
- [ ] å®šæœŸä¿å­˜checkpoint
- [ ] è®°å½•è®­ç»ƒæ—¶é•¿å’Œæ€§èƒ½

**è®­ç»ƒå®Œæˆå**ï¼š

- [ ] å¿«é€ŸåŠŸèƒ½æµ‹è¯•é€šè¿‡
- [ ] æ¨¡å‹å¯¹æ¯”éªŒè¯ï¼ˆF1 â‰¥ 60%ï¼‰
- [ ] ä¿å­˜æœ€ç»ˆæ¨¡å‹
- [ ] è®°å½•è®­ç»ƒé…ç½®å’Œç»“æœ

---

## ğŸ“§ æ”¯æŒä¸åé¦ˆ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š

1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„ **å¸¸è§é—®é¢˜** ç« èŠ‚
2. æŸ¥çœ‹é¡¹ç›®çš„ `EPIC_2_COMPLETION_REPORT.md`
3. æ£€æŸ¥è®­ç»ƒæ—¥å¿—ï¼š`logs/train_17pii_full_*.log`

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æ›´æ–°æ—¥æœŸ**: 2025-10-18
**é€‚ç”¨æ¨¡å‹**: Qwen2.5-3B-Instruct + LoRA (17ç§PII)
