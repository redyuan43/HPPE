# PII éšç§ç½‘å…³æ¶æ„è®¾è®¡

**åœºæ™¯ï¼š** æœ¬åœ°æ•°æ® â†’ è„±æ• â†’ äº‘ç«¯ LLM â†’ è¿˜åŸ â†’ è¿”å›ç”¨æˆ·
**ç›®æ ‡ï¼š** åµŒå…¥å¼è®¾å¤‡éƒ¨ç½²ï¼Œ99% å‡†ç¡®ç‡ï¼Œéšç§ä¼˜å…ˆ
**å·¥ä½œè´Ÿè½½ï¼š** 70% æ‰¹å¤„ç†ï¼Œ30% å®æ—¶

---

## æ ¸å¿ƒéœ€æ±‚åˆ†æ

### 1. æ•°æ®æµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â‘ æ£€æµ‹    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â‘¡è„±æ•    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç”¨æˆ·æ•°æ® â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â†’   â”‚ HPPEå¼•æ“ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â†’   â”‚ è„±æ•æ•°æ® â”‚
â”‚          â”‚             â”‚          â”‚             â”‚          â”‚
â”‚ "æˆ‘å«å¼ ä¸‰â”‚             â”‚ æ£€æµ‹åˆ°:  â”‚             â”‚ "æˆ‘å«[P1]â”‚
â”‚  åœ¨æ¸…å  â”‚             â”‚ - å¼ ä¸‰   â”‚             â”‚  åœ¨[O1]  â”‚
â”‚  å¤§å­¦"   â”‚             â”‚ - æ¸…åå¤§å­¦â”‚            â”‚  [O1]"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   æ˜ å°„è¡¨ï¼ˆåŠ å¯†ï¼‰ â”‚
                    â”‚  P1 â†’ å¼ ä¸‰      â”‚
                    â”‚  O1 â†’ æ¸…åå¤§å­¦   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â‘£è¿˜åŸ    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚äº‘ç«¯LLM   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â†’    â”‚ HPPEå¼•æ“ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â†’   â”‚ åŸå§‹æ•°æ® â”‚
â”‚å¤„ç†ç»“æœ  â”‚    â‘¢è¿”å›     â”‚          â”‚             â”‚          â”‚
â”‚"[P1]æ˜¯   â”‚              â”‚ æŸ¥æ˜ å°„è¡¨: â”‚             â”‚"å¼ ä¸‰æ˜¯   â”‚
â”‚ [O1]çš„   â”‚              â”‚ P1â†’å¼ ä¸‰  â”‚             â”‚ æ¸…åå¤§å­¦ â”‚
â”‚ å­¦ç”Ÿ"    â”‚              â”‚ O1â†’æ¸…åå¤§å­¦â”‚            â”‚ çš„å­¦ç”Ÿ"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æ ¸å¿ƒæŒ‘æˆ˜

**å‡†ç¡®ç‡è¦æ±‚ï¼ˆ99%ï¼‰ï¼š**
- âŒ æ¼æ£€ 1% â†’ æ•æ„Ÿä¿¡æ¯æ³„éœ²åˆ°äº‘ç«¯
- âŒ è¯¯æŠ¥ 1% â†’ æ­£å¸¸æ–‡æœ¬è¢«æ›¿æ¢ï¼Œè¯­ä¹‰æŸå

**åµŒå…¥å¼çº¦æŸï¼š**
- æœ‰é™çš„ CPU/å†…å­˜/å­˜å‚¨
- å¯èƒ½æ²¡æœ‰ GPU
- ç”µæ± ä¾›ç”µï¼ˆåŠŸè€—æ•æ„Ÿï¼‰

**éšç§ä¿æŠ¤ï¼š**
- æ˜ å°„è¡¨å¿…é¡»åŠ å¯†å­˜å‚¨
- ä¸èƒ½å°†æ˜ å°„è¡¨å‘é€åˆ°äº‘ç«¯
- æœ¬åœ°å¤„ç†ä¼˜å…ˆ

---

## æ¶æ„è®¾è®¡

### é˜¶æ®µ 1ï¼šå½“å‰æœåŠ¡å™¨æ¶æ„ï¼ˆå·²å®ç°ï¼‰

**æŠ€æœ¯æ ˆï¼š**
- **æ£€æµ‹ï¼š** Regexï¼ˆç»“æ„åŒ–ï¼‰+ Qwen3-8Bï¼ˆéç»“æ„åŒ–ï¼‰
- **éƒ¨ç½²ï¼š** æœåŠ¡å™¨ + RTX 3060
- **å‡†ç¡®ç‡ï¼š** 100%ï¼ˆæµ‹è¯•æ•°æ®ï¼‰

**å±€é™ï¼š**
- ä¾èµ– 8B æ¨¡å‹ï¼ˆ16GB å†…å­˜ï¼‰
- ä¸é€‚åˆåµŒå…¥å¼è®¾å¤‡

### é˜¶æ®µ 2ï¼šåµŒå…¥å¼è¿‡æ¸¡æ¶æ„ï¼ˆæ¨èï¼‰

#### 2.1 æ··åˆå¤„ç†æ¨¡å¼

```python
class EmbeddedPIIGateway:
    """åµŒå…¥å¼ PII éšç§ç½‘å…³"""

    def __init__(self):
        # æœ¬åœ°ï¼šå¿«é€Ÿ Regex å¼•æ“
        self.local_detector = RegexDetector()

        # å¯é€‰ï¼šè½»é‡ LLMï¼ˆ1-3Bï¼‰
        self.light_llm = Optional[Qwen2_1_5B]()

        # æ˜ å°„ç®¡ç†å™¨ï¼ˆåŠ å¯†ï¼‰
        self.mapper = EncryptedMapper()

    def anonymize(self, text: str, mode="safe"):
        """è„±æ•"""

        # ç¬¬ä¸€å±‚ï¼šæœ¬åœ° Regexï¼ˆå¿…é€‰ï¼Œæå¿«ï¼‰
        regex_entities = self.local_detector.detect(text)

        # ç¬¬äºŒå±‚ï¼šè½»é‡ LLMï¼ˆå¯é€‰ï¼Œè¾ƒæ…¢ï¼‰
        if mode == "safe" and self.light_llm:
            llm_entities = self.light_llm.detect(text)
            entities = merge(regex_entities, llm_entities)
        else:
            entities = regex_entities

        # ç”Ÿæˆæ›¿æ¢æ ‡è®° + ä¿å­˜æ˜ å°„
        anonymized, mapping = self._replace_entities(text, entities)
        self.mapper.store(mapping, encrypted=True)

        return anonymized

    def deanonymize(self, text: str, mapping_id: str):
        """è¿˜åŸ"""
        mapping = self.mapper.load(mapping_id, decrypt=True)
        return self._restore_entities(text, mapping)
```

#### 2.2 åˆ†çº§å¤„ç†ç­–ç•¥

```
è¾“å…¥æ–‡æœ¬
  â”‚
  â”œâ”€â†’ å¿«é€Ÿæ¨¡å¼ï¼ˆå®æ—¶ 30%ï¼‰
  â”‚     â””â”€â†’ ä»… Regexï¼ˆ< 1msï¼‰
  â”‚         â””â”€â†’ è¦†ç›–ç‡ 60%ï¼Œä½†é€Ÿåº¦æå¿«
  â”‚
  â””â”€â†’ å®‰å…¨æ¨¡å¼ï¼ˆæ‰¹å¤„ç† 70%ï¼‰
        â””â”€â†’ Regex + è½»é‡ LLMï¼ˆ1-3sï¼‰
            â””â”€â†’ è¦†ç›–ç‡ 95%ï¼Œå‡†ç¡®ç‡ 99%
```

**æƒè¡¡ï¼š**
- å®æ—¶åœºæ™¯ï¼šé€Ÿåº¦ä¼˜å…ˆï¼Œæ¥å— 60% è¦†ç›–ç‡
- æ‰¹å¤„ç†ï¼šå‡†ç¡®ç‡ä¼˜å…ˆï¼Œ99% è¦†ç›–ç‡

---

## æŠ€æœ¯è·¯çº¿å›¾

### Phase 1ï¼šè„±æ•/è¿˜åŸåŠŸèƒ½ï¼ˆç«‹å³å®æ–½ï¼‰

**ç›®æ ‡ï¼š** åœ¨ç°æœ‰ç³»ç»Ÿä¸Šæ·»åŠ è„±æ•å’Œè¿˜åŸåŠŸèƒ½

**å®ç°ï¼š**
```python
# 1. åˆ›å»ºè„±æ•å™¨
from hppe.privacy import PIIAnonymizer

anonymizer = PIIAnonymizer(
    detector=HybridPIIDetector(mode="deep"),
    strategy="pseudonymization"  # å‡ååŒ–
)

# 2. è„±æ•
text = "æˆ‘å«å¼ ä¸‰ï¼Œåœ¨æ¸…åå¤§å­¦å·¥ä½œï¼Œç”µè¯13800138000"
result = anonymizer.anonymize(text)

print(result.anonymized_text)
# "æˆ‘å«[PERSON_1]ï¼Œåœ¨[ORG_1]å·¥ä½œï¼Œç”µè¯[PHONE_1]"

print(result.mapping)
# {
#   "PERSON_1": "å¼ ä¸‰",
#   "ORG_1": "æ¸…åå¤§å­¦",
#   "PHONE_1": "13800138000"
# }

# 3. å‘é€åˆ°äº‘ç«¯ LLM
cloud_response = cloud_llm.generate(result.anonymized_text)
# "[PERSON_1]æ˜¯[ORG_1]çš„æ•™æˆ"

# 4. è¿˜åŸ
original = anonymizer.deanonymize(
    cloud_response,
    result.mapping
)
print(original)
# "å¼ ä¸‰æ˜¯æ¸…åå¤§å­¦çš„æ•™æˆ"
```

**ä¼˜å…ˆçº§ï¼š** â­â­â­â­â­ æœ€é«˜
**æ—¶é—´ï¼š** 1-2 å‘¨
**éš¾åº¦ï¼š** ğŸŸ¢ ç®€å•

---

### Phase 2ï¼šæ¨¡å‹è’¸é¦ï¼ˆ3-6 ä¸ªæœˆï¼‰

**ç›®æ ‡ï¼š** Qwen3-8B â†’ Qwen2-1.5Bï¼Œé€‚é…åµŒå…¥å¼

#### 2.1 æ•°æ®å‡†å¤‡

```python
# ä½¿ç”¨ Qwen3-8B ç”Ÿæˆè®­ç»ƒæ•°æ®
teacher_model = Qwen3_8B()

training_data = []
for text in diverse_corpus:  # 10-50ä¸‡æ ·æœ¬
    entities = teacher_model.detect(text)
    training_data.append({
        "text": text,
        "labels": entities  # ä½ç½® + ç±»å‹ + ç½®ä¿¡åº¦
    })
```

**æ•°æ®å¤šæ ·æ€§ï¼š**
- ç¤¾äº¤åª’ä½“æ–‡æœ¬ï¼ˆç®€çŸ­ã€å£è¯­åŒ–ï¼‰
- æ­£å¼æ–‡æ¡£ï¼ˆå®Œæ•´ã€è§„èŒƒï¼‰
- å¯¹è¯è®°å½•ï¼ˆå¤šè½®ã€ä¸Šä¸‹æ–‡ï¼‰
- è¾¹ç•Œæ¡ˆä¾‹ï¼ˆæ¨¡ç³Šã€å›°éš¾ï¼‰

#### 2.2 è’¸é¦è®­ç»ƒ

```python
# LoRA å¾®è°ƒï¼ˆå‚æ•°é«˜æ•ˆï¼‰
from peft import LoraConfig, get_peft_model

student_model = Qwen2_1_5B()

lora_config = LoraConfig(
    r=8,  # LoRA ç§©
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05
)

# çŸ¥è¯†è’¸é¦æŸå¤±
loss = (
    0.5 * task_loss +        # ä»»åŠ¡æŸå¤±
    0.3 * kl_divergence +    # ä¸æ•™å¸ˆæ¨¡å‹çš„ KL æ•£åº¦
    0.2 * feature_matching  # ä¸­é—´ç‰¹å¾åŒ¹é…
)
```

**é¢„æœŸç»“æœï¼š**
- **æ¨¡å‹å¤§å°ï¼š** 8B â†’ 1.5Bï¼ˆå‡å°‘ 81%ï¼‰
- **å†…å­˜å ç”¨ï¼š** 16GB â†’ 3GB
- **å»¶è¿Ÿï¼š** 8.9s â†’ 2-3s
- **å‡†ç¡®ç‡ï¼š** 100% â†’ 97-99%

**é€‚é…åµŒå…¥å¼ï¼š**
```
è®¾å¤‡ç±»å‹           CPU            å†…å­˜      æ¨¡å‹é€‰æ‹©
-------------------------------------------------
é«˜ç«¯ (æ ‘è“æ´¾5)     Cortex-A76    8GB      Qwen2-1.5B (INT8)
ä¸­ç«¯ (Jetson Nano) Maxwell GPU   4GB      Qwen2-0.5B (INT4)
ä½ç«¯ (ESP32)       Xtensa        512KB    ä»… Regex
```

---

### Phase 3ï¼šéšç§ä¿æŠ¤æœºåˆ¶ï¼ˆå¹¶è¡Œå®æ–½ï¼‰

#### 3.1 æ˜ å°„è¡¨åŠ å¯†

```python
from cryptography.fernet import Fernet
import hashlib

class EncryptedMapper:
    def __init__(self, master_key: bytes):
        self.cipher = Fernet(master_key)

    def store(self, mapping: dict, session_id: str):
        """åŠ å¯†å­˜å‚¨æ˜ å°„è¡¨"""

        # åºåˆ—åŒ–
        data = json.dumps(mapping).encode()

        # åŠ å¯†
        encrypted = self.cipher.encrypt(data)

        # å­˜å‚¨ï¼ˆæœ¬åœ° SQLite / Redisï¼‰
        db.set(
            f"mapping:{session_id}",
            encrypted,
            expire=3600  # 1å°æ—¶åè‡ªåŠ¨åˆ é™¤
        )

    def load(self, session_id: str) -> dict:
        """è§£å¯†è¯»å–æ˜ å°„è¡¨"""
        encrypted = db.get(f"mapping:{session_id}")
        data = self.cipher.decrypt(encrypted)
        return json.loads(data)
```

#### 3.2 å®‰å…¨ä¼ è¾“

```python
# æ–¹æ¡ˆ Aï¼šå®¢æˆ·ç«¯åŠ å¯†ï¼ˆæ¨èï¼‰
class ClientSideEncryption:
    """å®¢æˆ·ç«¯å®Œå…¨æ§åˆ¶å¯†é’¥"""

    def __init__(self):
        # å¯†é’¥æ°¸ä¸ç¦»å¼€å®¢æˆ·ç«¯
        self.key = generate_key()

    def process(self, text):
        # 1. æœ¬åœ°æ£€æµ‹ + è„±æ•
        anonymized, mapping = detect_and_anonymize(text)

        # 2. åŠ å¯†æ˜ å°„è¡¨ï¼ˆæœ¬åœ°ï¼‰
        encrypted_mapping = encrypt(mapping, self.key)

        # 3. å‘é€åˆ°äº‘ç«¯ï¼ˆä»…è„±æ•æ–‡æœ¬ï¼‰
        response = cloud_llm(anonymized)

        # 4. æœ¬åœ°è¿˜åŸ
        original = deanonymize(response, mapping)

        return original

# æ–¹æ¡ˆ Bï¼šé›¶çŸ¥è¯†è¯æ˜ï¼ˆé«˜çº§ï¼‰
# - è¯æ˜æ•°æ®å·²è„±æ•ï¼Œä½†ä¸æ³„éœ²æ˜ å°„å…³ç³»
# - é€‚ç”¨äºåˆè§„å®¡è®¡åœºæ™¯
```

#### 3.3 éšç§ä¿æŠ¤ç­‰çº§

```python
class PrivacyLevel(Enum):
    """éšç§ä¿æŠ¤ç­‰çº§"""

    # L1ï¼šåŸºç¡€ï¼ˆå¿«é€Ÿï¼‰
    BASIC = "regex_only"
    # - ä»…æ£€æµ‹ç»“æ„åŒ– PII
    # - é€‚ç”¨äºï¼šæ—¥å¿—è®°å½•ã€ç›‘æ§

    # L2ï¼šæ ‡å‡†ï¼ˆå¹³è¡¡ï¼‰
    STANDARD = "hybrid"
    # - Regex + è½»é‡ LLM
    # - é€‚ç”¨äºï¼šä¸€èˆ¬ç”¨æˆ·æ•°æ®

    # L3ï¼šä¸¥æ ¼ï¼ˆæœ€å®‰å…¨ï¼‰
    STRICT = "conservative"
    # - ä¿å®ˆç­–ç•¥ï¼šå®å¯è¯¯æŠ¥
    # - äººå·¥å®¡æ ¸è¾…åŠ©
    # - é€‚ç”¨äºï¼šåŒ»ç–—ã€é‡‘èæ•°æ®
```

---

## åµŒå…¥å¼ä¼˜åŒ–ç­–ç•¥

### 1. æ¨¡å‹é‡åŒ–

```python
# INT8 é‡åŒ–ï¼ˆæ¨èï¼‰
from optimum.quanto import quantize, freeze

model = Qwen2_1_5B()
quantize(model, weights=qint8)
freeze(model)

# æ•ˆæœï¼š
# - æ¨¡å‹å¤§å°ï¼š3GB â†’ 1.5GB
# - é€Ÿåº¦æå‡ï¼š+30%
# - å‡†ç¡®ç‡ï¼š99.5% â†’ 99%

# INT4 é‡åŒ–ï¼ˆæ¿€è¿›ï¼‰
quantize(model, weights=qint4)
# - æ¨¡å‹å¤§å°ï¼š3GB â†’ 0.75GB
# - é€Ÿåº¦æå‡ï¼š+50%
# - å‡†ç¡®ç‡ï¼š99.5% â†’ 97%ï¼ˆéœ€éªŒè¯ï¼‰
```

### 2. æ¨¡å‹å‰ªæ

```python
# ç§»é™¤ä¸é‡è¦çš„ç¥ç»å…ƒ
from torch.nn.utils import prune

# ç»“æ„åŒ–å‰ªæ
prune.ln_structured(
    model.layers,
    name="weight",
    amount=0.3,  # å‰ªæ 30%
    n=2,
    dim=0
)

# æ•ˆæœï¼š
# - æ¨¡å‹å¤§å°ï¼š-30%
# - å»¶è¿Ÿï¼š-25%
# - å‡†ç¡®ç‡ï¼š-1-2%
```

### 3. çŸ¥è¯†è’¸é¦ï¼ˆæ¨èï¼‰

```python
# æ–¹æ¡ˆï¼š8B æ•™å¸ˆ â†’ 1.5B å­¦ç”Ÿ

# æ•°æ®ç”Ÿæˆ
teacher = Qwen3_8B()
student = Qwen2_1_5B()

for text in corpus:
    # æ•™å¸ˆæ¨¡å‹çš„è¾“å‡º
    teacher_logits = teacher(text)
    teacher_entities = extract_entities(teacher_logits)

    # å­¦ç”Ÿæ¨¡å‹è®­ç»ƒ
    student_logits = student(text)

    # è’¸é¦æŸå¤±
    loss = (
        alpha * hard_loss(student_entities, true_entities) +
        (1-alpha) * soft_loss(student_logits, teacher_logits)
    )

    optimize(loss)
```

---

## æ‰¹å¤„ç†ä¼˜åŒ–ï¼ˆ70% åœºæ™¯ï¼‰

### 1. æ‰¹é‡è„±æ•

```python
class BatchAnonymizer:
    def anonymize_batch(
        self,
        texts: List[str],
        batch_size: int = 32
    ) -> List[AnonymizationResult]:
        """æ‰¹é‡è„±æ•"""

        results = []

        # Regex æ‰¹å¤„ç†ï¼ˆå¹¶è¡Œï¼‰
        with ThreadPoolExecutor(max_workers=8) as executor:
            regex_futures = [
                executor.submit(self.regex_detect, text)
                for text in texts
            ]
            regex_results = [f.result() for f in regex_futures]

        # LLM æ‰¹å¤„ç†ï¼ˆåˆ†æ‰¹ï¼‰
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]

            # è½»é‡ LLM å¯èƒ½æ”¯æŒæ‰¹é‡æ¨ç†
            if self.light_llm.supports_batch:
                llm_results = self.light_llm.detect_batch(batch)
            else:
                llm_results = [
                    self.light_llm.detect(t) for t in batch
                ]

            # åˆå¹¶ç»“æœ
            for j, text in enumerate(batch):
                entities = merge(
                    regex_results[i+j],
                    llm_results[j]
                )
                result = self._anonymize_single(text, entities)
                results.append(result)

        return results
```

### 2. æµå¼å¤„ç†

```python
def process_large_dataset(
    input_file: str,
    output_file: str,
    chunk_size: int = 1000
):
    """æµå¼å¤„ç†å¤§æ–‡ä»¶"""

    anonymizer = BatchAnonymizer()

    with open(input_file, 'r') as fin, \
         open(output_file, 'w') as fout, \
         open('mappings.db', 'w') as fmap:

        while True:
            # è¯»å–ä¸€æ‰¹
            chunk = [fin.readline() for _ in range(chunk_size)]
            if not chunk[0]:
                break

            # æ‰¹é‡å¤„ç†
            results = anonymizer.anonymize_batch(chunk)

            # å†™å…¥ç»“æœ
            for result in results:
                fout.write(result.anonymized_text + '\n')
                fmap.write(json.dumps(result.mapping) + '\n')
```

---

## æ€§èƒ½é¢„æµ‹

### å½“å‰æ¶æ„ï¼ˆæœåŠ¡å™¨ï¼‰

| æŒ‡æ ‡ | Regex | LLM (8B) | æ··åˆ |
|------|-------|----------|------|
| å»¶è¿Ÿï¼ˆå•ä¸ªï¼‰ | 0.02ms | 8.9s | 8.9s |
| ååé‡ï¼ˆæ‰¹å¤„ç†ï¼‰ | 18K/s | 0.06/s | 0.06/s |
| è¦†ç›–ç‡ | 60% | 95% | 95% |
| å‡†ç¡®ç‡ | 100% | 100% | 100% |

### ç›®æ ‡æ¶æ„ï¼ˆåµŒå…¥å¼ï¼‰

| æŒ‡æ ‡ | Regex | è½»é‡LLM (1.5B) | æ··åˆ |
|------|-------|----------------|------|
| å»¶è¿Ÿï¼ˆå•ä¸ªï¼‰ | 0.05ms | 2-3s | 3s |
| ååé‡ï¼ˆæ‰¹å¤„ç†ï¼‰ | 10K/s | 0.3-0.5/s | 0.5/s |
| è¦†ç›–ç‡ | 60% | 90% | 90% |
| å‡†ç¡®ç‡ | 100% | 97-99% | 98-99% |
| å†…å­˜å ç”¨ | <10MB | 2-3GB | 3GB |
| åŠŸè€— | <1W | 5-10W | 10W |

**é€‚é…è®¾å¤‡ï¼š**
- âœ… æ ‘è“æ´¾ 5ï¼ˆ8GB RAMï¼‰
- âœ… Jetson Nanoï¼ˆ4GB RAMï¼ŒGPUï¼‰
- âŒ ESP32ï¼ˆå†…å­˜å¤ªå°ï¼Œä»… Regexï¼‰

---

## å®æ–½å»ºè®®

### ä¼˜å…ˆçº§ 1ï¼ˆç«‹å³ï¼Œ1-2å‘¨ï¼‰ï¼š
1. **è„±æ•/è¿˜åŸåŠŸèƒ½** â­â­â­â­â­
   - åŸºäºç°æœ‰æ£€æµ‹å™¨
   - æ·»åŠ æ˜ å°„ç®¡ç†
   - åŠ å¯†å­˜å‚¨

### ä¼˜å…ˆçº§ 2ï¼ˆè¿‘æœŸï¼Œ1-2ä¸ªæœˆï¼‰ï¼š
2. **æ‰¹å¤„ç†ä¼˜åŒ–** â­â­â­â­â­
   - é’ˆå¯¹ 70% æ‰¹å¤„ç†åœºæ™¯
   - æµå¼å¤„ç†å¤§æ–‡ä»¶
   - æ€§èƒ½ç›‘æ§

3. **éšç§ä¿æŠ¤æœºåˆ¶** â­â­â­â­â­
   - å®¢æˆ·ç«¯åŠ å¯†
   - å®‰å…¨ä¼ è¾“
   - åˆè§„å®¡è®¡æ—¥å¿—

### ä¼˜å…ˆçº§ 3ï¼ˆä¸­æœŸï¼Œ3-6ä¸ªæœˆï¼‰ï¼š
4. **æ¨¡å‹è’¸é¦** â­â­â­â­â­
   - æ•°æ®æ”¶é›†ï¼ˆ10-50ä¸‡ï¼‰
   - è’¸é¦è®­ç»ƒ
   - å‡†ç¡®ç‡éªŒè¯ï¼ˆç›®æ ‡ 99%ï¼‰

### ä¼˜å…ˆçº§ 4ï¼ˆé•¿æœŸï¼Œ6-12ä¸ªæœˆï¼‰ï¼š
5. **åµŒå…¥å¼é€‚é…** â­â­â­â­
   - é‡åŒ–ä¼˜åŒ–
   - ARM æ¶æ„é€‚é…
   - åŠŸè€—ä¼˜åŒ–

---

## æŠ€æœ¯é€‰å‹å»ºè®®

### è½»é‡æ¨¡å‹å€™é€‰

1. **Qwen2-1.5B** â­â­â­â­â­ï¼ˆæ¨èï¼‰
   - ä¼˜åŠ¿ï¼šä¸­æ–‡ä¼˜ç§€ï¼Œå®˜æ–¹æ”¯æŒ
   - å†…å­˜ï¼š~3GB
   - é€Ÿåº¦ï¼š2-3s/æ¬¡
   - é€‚é…ï¼šæ ‘è“æ´¾ 5ã€Jetson

2. **Qwen2-0.5B** â­â­â­â­
   - ä¼˜åŠ¿ï¼šæ›´å°æ›´å¿«
   - å†…å­˜ï¼š~1GB
   - é€Ÿåº¦ï¼š0.5-1s/æ¬¡
   - å‡†ç¡®ç‡ï¼šå¯èƒ½ç•¥ä½ï¼ˆéœ€éªŒè¯ï¼‰

3. **ä»… Regex** â­â­â­
   - ä¼˜åŠ¿ï¼šæå¿«ï¼Œæ— ä¾èµ–
   - è¦†ç›–ç‡ï¼š60%
   - é€‚ç”¨ï¼šä½ç«¯è®¾å¤‡ã€å®æ—¶åœºæ™¯

### éƒ¨ç½²æ–¹æ¡ˆ

```python
# é…ç½®æ–‡ä»¶é©±åŠ¨
config = {
    "deployment": {
        "device_type": "raspberry_pi_5",  # æˆ– jetson, server
        "model": "qwen2-1.5b-int8",
        "privacy_level": "standard",
        "batch_size": 16
    },
    "realtime": {
        "mode": "fast",  # ä»… Regex
        "timeout_ms": 100
    },
    "batch": {
        "mode": "safe",  # Regex + LLM
        "chunk_size": 1000
    }
}
```

---

## æ€»ç»“

ä½ çš„åœºæ™¯æ˜¯ä¸€ä¸ª **éšç§ä¿æŠ¤çš„æ™ºèƒ½ç½‘å…³**ï¼Œæ ¸å¿ƒè¦æ±‚æ˜¯ï¼š

1. âœ… **99% å‡†ç¡®ç‡** - é€šè¿‡æ¨¡å‹è’¸é¦ + éªŒè¯é›†æµ‹è¯•ä¿è¯
2. âœ… **éšç§ä¼˜å…ˆ** - å®¢æˆ·ç«¯åŠ å¯† + æœ¬åœ°å¤„ç†
3. âœ… **æ‰¹å¤„ç†ä¼˜åŒ–** - æµå¼å¤„ç† + å¹¶è¡ŒåŒ–ï¼ˆ70% åœºæ™¯ï¼‰
4. âœ… **åµŒå…¥å¼å°±ç»ª** - æ¨¡å‹è’¸é¦åˆ° 1.5Bï¼Œé‡åŒ–åˆ° INT8

**å…³é”®è·¯å¾„ï¼š**
```
å½“å‰ï¼ˆæœåŠ¡å™¨ + 8Bï¼‰
  â†“ 1-2å‘¨
æ·»åŠ è„±æ•/è¿˜åŸåŠŸèƒ½
  â†“ 1-2ä¸ªæœˆ
æ‰¹å¤„ç† + éšç§ä¼˜åŒ–
  â†“ 3-6ä¸ªæœˆ
æ¨¡å‹è’¸é¦ï¼ˆ8B â†’ 1.5Bï¼‰
  â†“ 6-12ä¸ªæœˆ
åµŒå…¥å¼è®¾å¤‡éƒ¨ç½²
```

**ä¸‹ä¸€æ­¥ï¼š** æˆ‘å»ºè®®å…ˆå®ç°è„±æ•/è¿˜åŸåŠŸèƒ½ï¼Œåˆ›å»ºå®Œæ•´çš„æ•°æ®æµã€‚ä½ è§‰å¾—å¦‚ä½•ï¼Ÿ
