#!/usr/bin/env python3
"""
å°† BIO æ ¼å¼çš„ NER æ•°æ®è½¬æ¢ä¸º SFT è®­ç»ƒæ ¼å¼

è¾“å…¥æ ¼å¼ï¼ˆBIOï¼‰ï¼š
å½“ O
å¸Œ O
æœ› O
å·¥ O
ç¨‹ O
æ•‘ O
åŠ© O

è¾“å‡ºæ ¼å¼ï¼ˆSFTï¼‰ï¼š
{
  "instruction": "æ£€æµ‹ä»¥ä¸‹æ–‡æœ¬ä¸­çš„ PIIï¼Œå¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºå®ä½“åˆ—è¡¨ã€‚",
  "input": "å½“å¸Œæœ›å·¥ç¨‹æ•‘åŠ©",
  "output": {
    "entities": [...]
  }
}
"""

import argparse
import json
import sys
from pathlib import Path
from typing import List, Dict, Any

# PIIç±»å‹æ˜ å°„
ENTITY_TYPE_MAPPING = {
    "PER": "PERSON_NAME",
    "LOC": "ADDRESS",
    "ORG": "ORGANIZATION",
    "GPE": "ADDRESS",  # Geo-Political Entity
}


def parse_bio_file(file_path: Path) -> List[List[tuple]]:
    """
    è§£æ BIO æ ¼å¼æ–‡ä»¶

    Returns:
        å¥å­åˆ—è¡¨ï¼Œæ¯ä¸ªå¥å­æ˜¯ [(å­—ç¬¦, æ ‡ç­¾), ...] çš„åˆ—è¡¨
    """
    sentences = []
    current_sentence = []

    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()

            if not line:
                # ç©ºè¡Œè¡¨ç¤ºå¥å­ç»“æŸ
                if current_sentence:
                    sentences.append(current_sentence)
                    current_sentence = []
                continue

            # è§£æï¼šå­—ç¬¦\tæ ‡ç­¾
            parts = line.split()
            if len(parts) >= 2:
                char = parts[0]
                tag = parts[1]
                current_sentence.append((char, tag))

        # æ·»åŠ æœ€åä¸€ä¸ªå¥å­
        if current_sentence:
            sentences.append(current_sentence)

    return sentences


def convert_bio_sentence_to_sft(sentence: List[tuple]) -> Dict[str, Any]:
    """
    å°† BIO æ ¼å¼çš„å¥å­è½¬æ¢ä¸º SFT æ ¼å¼

    Args:
        sentence: [(å­—ç¬¦, æ ‡ç­¾), ...] åˆ—è¡¨

    Returns:
        SFT æ ¼å¼çš„æ ·æœ¬
    """
    # é‡å»ºæ–‡æœ¬
    text = "".join([char for char, tag in sentence])

    # æå–å®ä½“
    entities = []
    current_entity = None
    current_start = 0

    for i, (char, tag) in enumerate(sentence):
        if tag.startswith("B-"):
            # ä¿å­˜ä¹‹å‰çš„å®ä½“
            if current_entity:
                entity_type = ENTITY_TYPE_MAPPING.get(
                    current_entity["raw_type"],
                    current_entity["raw_type"]
                )
                entities.append({
                    "type": entity_type,
                    "value": current_entity["value"],
                    "start": current_entity["start"],
                    "end": current_entity["end"]
                })

            # å¼€å§‹æ–°å®ä½“
            raw_type = tag[2:]  # PER, ORG, LOC, etc.
            current_entity = {
                "raw_type": raw_type,
                "value": char,
                "start": i,
                "end": i + 1
            }

        elif tag.startswith("I-") and current_entity:
            # ç»§ç»­å½“å‰å®ä½“
            current_entity["value"] += char
            current_entity["end"] = i + 1

        else:  # O
            # ä¿å­˜ä¹‹å‰çš„å®ä½“
            if current_entity:
                entity_type = ENTITY_TYPE_MAPPING.get(
                    current_entity["raw_type"],
                    current_entity["raw_type"]
                )
                entities.append({
                    "type": entity_type,
                    "value": current_entity["value"],
                    "start": current_entity["start"],
                    "end": current_entity["end"]
                })
                current_entity = None

    # ä¿å­˜æœ€åçš„å®ä½“
    if current_entity:
        entity_type = ENTITY_TYPE_MAPPING.get(
            current_entity["raw_type"],
            current_entity["raw_type"]
        )
        entities.append({
            "type": entity_type,
            "value": current_entity["value"],
            "start": current_entity["start"],
            "end": current_entity["end"]
        })

    # æ„å»º SFT æ ¼å¼
    return {
        "instruction": "æ£€æµ‹ä»¥ä¸‹æ–‡æœ¬ä¸­çš„ PIIï¼Œå¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºå®ä½“åˆ—è¡¨ã€‚",
        "input": text,
        "output": {
            "entities": entities
        }
    }


def convert_bio_to_sft(
    input_file: Path,
    output_file: Path,
    max_samples: int = None,
    show_progress: bool = True
) -> int:
    """
    è½¬æ¢ BIO æ–‡ä»¶ä¸º SFT æ ¼å¼

    Returns:
        è½¬æ¢çš„æ ·æœ¬æ•°
    """
    print(f"\nè½¬æ¢ BIO æ–‡ä»¶: {input_file.name}")
    print(f"è¾“å‡º: {output_file}")

    # è§£æ BIO æ–‡ä»¶
    print(f"\nè¯»å– BIO æ–‡ä»¶...")
    sentences = parse_bio_file(input_file)
    print(f"  âœ“ è¯»å–äº† {len(sentences)} ä¸ªå¥å­")

    if max_samples:
        sentences = sentences[:max_samples]
        print(f"  é™åˆ¶æ ·æœ¬æ•°: {len(sentences)}")

    # è½¬æ¢ä¸º SFT æ ¼å¼
    print(f"\nè½¬æ¢ä¸º SFT æ ¼å¼...")
    sft_samples = []
    samples_with_entities = 0

    for i, sentence in enumerate(sentences):
        if show_progress and (i + 1) % 10000 == 0:
            print(f"  è¿›åº¦: {i + 1}/{len(sentences)}", end="\r")

        sft_sample = convert_bio_sentence_to_sft(sentence)

        # åªä¿ç•™åŒ…å«å®ä½“çš„æ ·æœ¬
        if sft_sample["output"]["entities"]:
            sft_samples.append(sft_sample)
            samples_with_entities += 1

    if show_progress:
        print(f"  è¿›åº¦: {len(sentences)}/{len(sentences)}")

    print(f"\nâœ“ è½¬æ¢å®Œæˆ")
    print(f"  æ€»å¥å­æ•°: {len(sentences)}")
    print(f"  æœ‰å®ä½“çš„: {samples_with_entities}")
    print(f"  è½¬æ¢ç‡: {samples_with_entities / len(sentences) * 100:.1f}%")

    # ç»Ÿè®¡å®ä½“ç±»å‹
    entity_type_counts = {}
    for sample in sft_samples:
        for entity in sample["output"]["entities"]:
            entity_type = entity["type"]
            entity_type_counts[entity_type] = entity_type_counts.get(entity_type, 0) + 1

    print(f"\nå®ä½“ç±»å‹åˆ†å¸ƒ:")
    for entity_type, count in sorted(entity_type_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = count / sum(entity_type_counts.values()) * 100
        print(f"  {entity_type}: {count} ({percentage:.1f}%)")

    # ä¿å­˜åˆ°æ–‡ä»¶
    print(f"\nä¿å­˜åˆ°æ–‡ä»¶...")
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, "w", encoding="utf-8") as f:
        for sample in sft_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + "\n")

    print(f"  âœ“ å·²ä¿å­˜åˆ°: {output_file}")

    # æ˜¾ç¤ºç¤ºä¾‹
    if sft_samples:
        print(f"\nç¤ºä¾‹æ•°æ®:")
        example = sft_samples[0]
        print(f"  è¾“å…¥: {example['input'][:50]}...")
        print(f"  å®ä½“æ•°: {len(example['output']['entities'])}")
        if example['output']['entities']:
            print(f"  å®ä½“: {[(e['type'], e['value']) for e in example['output']['entities'][:3]]}")

    return len(sft_samples)


def main():
    parser = argparse.ArgumentParser(
        description="å°† BIO æ ¼å¼çš„ NER æ•°æ®è½¬æ¢ä¸º SFT è®­ç»ƒæ ¼å¼",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="è¾“å…¥çš„ BIO æ ¼å¼æ–‡ä»¶"
    )

    parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="è¾“å‡ºçš„ JSONL æ–‡ä»¶"
    )

    parser.add_argument(
        "--max-samples",
        type=int,
        help="æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰"
    )

    args = parser.parse_args()

    input_file = Path(args.input)
    output_file = Path(args.output)

    if not input_file.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        sys.exit(1)

    # è½¬æ¢
    num_samples = convert_bio_to_sft(
        input_file,
        output_file,
        max_samples=args.max_samples,
        show_progress=True
    )

    print(f"\nğŸ‰ è½¬æ¢å®Œæˆï¼å…± {num_samples} ä¸ªæ ·æœ¬")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\n\nâŒ å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
