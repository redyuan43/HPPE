#!/bin/bash

###############################################################################
# Qwen2.5 æ¨¡å‹æ‰¹é‡ä¸‹è½½è„šæœ¬
#
# æ ¹æ® RTX 3060 12GB æ˜¾å­˜ï¼Œæ¨èä¸‹è½½é¡ºåºï¼š
# 1. Qwen2.5-3B-Instruct-AWQ (å¼€å‘æµ‹è¯•)
# 2. Qwen2.5-7B-Instruct-AWQ (ç”Ÿäº§éƒ¨ç½²)
#
# ä½¿ç”¨æ–¹æ³•:
#   ./scripts/download_qwen_models.sh
#   æˆ–åå°è¿è¡Œ:
#   nohup ./scripts/download_qwen_models.sh > qwen_download.log 2>&1 &
###############################################################################

set -e

# é¢œè‰²è¾“å‡º
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
RED='\033[0;31m'
NC='\033[0m'

# æ—¥å¿—å‡½æ•°
log() {
    echo -e "${BLUE}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} $1"
}

info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ conda ç¯å¢ƒ
if ! command -v conda &> /dev/null; then
    error "conda æœªæ‰¾åˆ°ï¼Œè¯·å…ˆå®‰è£… Anaconda"
    exit 1
fi

# æ¿€æ´»ç¯å¢ƒ
log "æ¿€æ´» conda ç¯å¢ƒ..."
source "$(conda info --base)/etc/profile.d/conda.sh"
conda activate hppe || {
    error "æ— æ³•æ¿€æ´» hppe ç¯å¢ƒï¼Œè¯·å…ˆè¿è¡Œ ./scripts/setup_vllm_env.sh"
    exit 1
}

info "âœ“ ç¯å¢ƒå·²æ¿€æ´»: hppe"

# æ£€æŸ¥ç£ç›˜ç©ºé—´
log "æ£€æŸ¥ç£ç›˜ç©ºé—´..."
AVAILABLE_SPACE=$(df -BG /home/ivan | tail -1 | awk '{print $4}' | sed 's/G//')
REQUIRED_SPACE=15  # éœ€è¦çº¦ 15GB (3B: 2GB + 7B: 4.5GB + ç¼“å­˜)

if [ "$AVAILABLE_SPACE" -lt "$REQUIRED_SPACE" ]; then
    warn "ç£ç›˜ç©ºé—´å¯èƒ½ä¸è¶³ï¼ˆå¯ç”¨: ${AVAILABLE_SPACE}GBï¼Œéœ€è¦: ${REQUIRED_SPACE}GBï¼‰"
    read -p "æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
else
    info "âœ“ ç£ç›˜ç©ºé—´å……è¶³: ${AVAILABLE_SPACE}GB"
fi

# å®‰è£… huggingface-hubï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
log "æ£€æŸ¥ huggingface-hub..."
if ! python -c "import huggingface_hub" 2>/dev/null; then
    info "å®‰è£… huggingface-hub..."
    pip install -U huggingface-hub
fi
info "âœ“ huggingface-hub å·²å°±ç»ª"

echo ""
echo "======================================================================"
echo "                    Qwen2.5 æ¨¡å‹ä¸‹è½½è®¡åˆ’"
echo "======================================================================"
echo ""
echo "æ ¹æ®ä½ çš„ RTX 3060 12GB æ˜¾å­˜ï¼Œæ¨èä¸‹è½½é¡ºåºï¼š"
echo ""
echo "1ï¸âƒ£  Qwen2.5-3B-Instruct-AWQ  (~2GB)"
echo "    - ç”¨é€”ï¼šå¼€å‘æµ‹è¯•ã€Prompt è°ƒè¯•"
echo "    - æ˜¾å­˜ï¼š~3-4GB"
echo "    - é€Ÿåº¦ï¼šå¿«é€ŸåŠ è½½ï¼Œé€‚åˆè¿­ä»£"
echo ""
echo "2ï¸âƒ£  Qwen2.5-7B-Instruct-AWQ  (~4.5GB)"
echo "    - ç”¨é€”ï¼šç”Ÿäº§éƒ¨ç½²ã€æ­£å¼æ£€æµ‹"
echo "    - æ˜¾å­˜ï¼š~5-6GB"
echo "    - æ€§èƒ½ï¼šæ›´å¥½çš„ç†è§£å’Œå‡†ç¡®ç‡"
echo ""
echo "======================================================================"
echo ""

read -p "å¼€å§‹ä¸‹è½½ï¼Ÿ(y/n) " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    info "å·²å–æ¶ˆä¸‹è½½"
    exit 0
fi

# ä¸‹è½½å‡½æ•°
download_model() {
    local MODEL_NAME=$1
    local MODEL_SIZE=$2

    log "å¼€å§‹ä¸‹è½½: $MODEL_NAME ($MODEL_SIZE)"
    echo ""

    # ä½¿ç”¨ Python ä¸‹è½½ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
    python -c "
from huggingface_hub import snapshot_download
import sys

try:
    print(f'æ­£åœ¨ä¸‹è½½ $MODEL_NAME...')
    model_path = snapshot_download(
        repo_id='$MODEL_NAME',
        resume_download=True,
        local_files_only=False
    )
    print(f'âœ“ ä¸‹è½½å®Œæˆ: {model_path}')
except KeyboardInterrupt:
    print('\\nä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­')
    sys.exit(130)
except Exception as e:
    print(f'âœ— ä¸‹è½½å¤±è´¥: {e}')
    sys.exit(1)
"

    if [ $? -eq 0 ]; then
        info "âœ“ $MODEL_NAME ä¸‹è½½æˆåŠŸ"

        # éªŒè¯æ¨¡å‹
        log "éªŒè¯æ¨¡å‹æ–‡ä»¶..."
        python -c "
from transformers import AutoConfig, AutoTokenizer

try:
    config = AutoConfig.from_pretrained('$MODEL_NAME')
    tokenizer = AutoTokenizer.from_pretrained('$MODEL_NAME')
    print(f'âœ“ æ¨¡å‹éªŒè¯é€šè¿‡')
    print(f'  å‚æ•°æ•°é‡: {config.num_parameters:,}')
    print(f'  è¯è¡¨å¤§å°: {len(tokenizer):,}')
except Exception as e:
    print(f'âœ— éªŒè¯å¤±è´¥: {e}')
    exit(1)
"
    else
        error "âœ— $MODEL_NAME ä¸‹è½½å¤±è´¥"
        return 1
    fi

    echo ""
}

# ä¸‹è½½æ¨¡å‹
echo ""
log "========== ä¸‹è½½ 1/2: Qwen2.5-3B-Instruct-AWQ =========="
download_model "Qwen/Qwen2.5-3B-Instruct-AWQ" "~2GB"

echo ""
log "========== ä¸‹è½½ 2/2: Qwen2.5-7B-Instruct-AWQ =========="
download_model "Qwen/Qwen2.5-7B-Instruct-AWQ" "~4.5GB"

# å®Œæˆ
echo ""
echo "======================================================================"
log "æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼"
echo "======================================================================"
echo ""

# æ˜¾ç¤ºæ¨¡å‹ä½ç½®
log "æ¨¡å‹å­˜å‚¨ä½ç½®:"
CACHE_DIR="${HF_HOME:-$HOME/.cache/huggingface/hub}"
echo "  $CACHE_DIR"
echo ""

# æ˜¾ç¤ºä½¿ç”¨æŒ‡å—
info "ä¸‹ä¸€æ­¥æ“ä½œ:"
echo ""
echo "1. å¯åŠ¨ vLLM æœåŠ¡ï¼ˆä½¿ç”¨ 3B æ¨¡å‹æµ‹è¯•ï¼‰:"
echo "   MODEL_NAME=Qwen/Qwen2.5-3B-Instruct-AWQ ./scripts/start_vllm.sh"
echo ""
echo "2. æˆ–ä½¿ç”¨ 7B æ¨¡å‹ï¼ˆç”Ÿäº§éƒ¨ç½²ï¼‰:"
echo "   MODEL_NAME=Qwen/Qwen2.5-7B-Instruct-AWQ ./scripts/start_vllm.sh"
echo ""
echo "3. æµ‹è¯• LLM å¼•æ“:"
echo "   PYTHONPATH=/home/ivan/HPPE/src python examples/llm_engine_example.py"
echo ""
echo "4. è¿è¡Œ PII æ£€æµ‹æµ‹è¯•:"
echo "   # (å¾…å®ç° Story 2.3)"
echo ""

log "å®Œæˆï¼ğŸ‰"
